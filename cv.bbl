\begin{thebibliography}{10}

\bibitem{anderson2023dissipativity}
\textbf{B.~G. Anderson}, S.~Sojoudi, and M.~Arcak,
  ``\href{https://brendon-anderson.github.io/files/publications/anderson2023dissipativity-long.pdf}{Dissipativity
  theory for evolutionary games on infinite strategy sets},'' {\em Under
  review}, 2023.
\newblock URL
  \url{https://brendon-anderson.github.io/files/publications/anderson2023dissipativity-long.pdf}.

\bibitem{anderson2023towards}
\textbf{B.~G. Anderson}, Z.~Ma, J.~Li, and S.~Sojoudi,
  ``\href{https://arxiv.org/pdf/2101.09306.pdf}{Towards optimal branching of
  linear and semidefinite relaxations for neural network robustness
  certification},'' {\em Under review}, 2023.
\newblock URL \url{https://arxiv.org/pdf/2101.09306.pdf}.

\bibitem{bai2023avoiding}
Y.~Bai, \textbf{B.~G. Anderson}, A.~Kim, and S.~Sojoudi,
  ``\href{https://bai-yt.github.io/files/publications/AdaptiveSmoothing_PrePrint.pdf}{Improving
  the accuracy-robustness trade-off of classifiers via adaptive smoothing},''
  {\em Under review}, 2023.
\newblock {\bf Second place method on
  \href{https://robustbench.github.io/#div_cifar100_Linf_heading}{RobustBench}
  CIFAR-100 $\ell_\infty$-leaderboard as of May 2023}. URL
  \url{https://bai-yt.github.io/files/publications/AdaptiveSmoothing_PrePrint.pdf}.

\bibitem{pfrommer2023asymmetric}
S.~Pfrommer*, \textbf{B.~G. Anderson*}, J.~Piet, and S.~Sojoudi,
  ``\href{https://arxiv.org/pdf/2302.01961.pdf}{Asymmetric certified robustness
  via feature-convex neural networks},'' in {\em Advances in Neural Information
  Processing Systems (NeurIPS)}, 2023.

\bibitem{pfrommer2023projected}
S.~Pfrommer, \textbf{B.~G. Anderson}, and S.~Sojoudi,
  ``\href{https://arxiv.org/pdf/2309.13794.pdf}{Projected randomized smoothing
  for certified adversarial robustness},'' {\em Transactions on Machine
  Learning Research (TMLR)}, 2023.
\newblock {\bf INFORMS Data Mining Best Student Paper Award Runner-Up}.

\bibitem{anderson2023tight}
\textbf{B.~G. Anderson}, S.~Pfrommer, and S.~Sojoudi,
  ``\href{https://arxiv.org/pdf/2310.04916.pdf}{Tight certified robustness via
  min-max representations of {ReLU} neural networks},'' in {\em Proceedings of
  the 62nd IEEE Conference on Decision and Control (CDC)}, 2023.

\bibitem{bai2023mixing}
Y.~Bai, \textbf{B.~G. Anderson}, and S.~Sojoudi,
  ``\href{https://bai-yt.github.io/files/publications/MixedClassifier_PrePrint.pdf}{Mixing
  classifiers to alleviate the accuracy-robustness trade-off},'' in {\em
  Proceedings of the 7th IEEE Conference on Control Technology and Applications
  (CCTA)}, 2023.

\bibitem{anderson2022overview}
\textbf{B.~G. Anderson*}, T.~Gautam*, and S.~Sojoudi,
  ``\href{https://people.eecs.berkeley.edu/~sojoudi/ifac_2022.pdf}{An overview
  and prospective outlook on robust training and certification of machine
  learning models},'' in {\em IFAC Symposium on System Structure and Control
  (SSSC)}, 2022.

\bibitem{gautam2022sequential}
T.~Gautam, \textbf{B.~G. Anderson}, S.~Sojoudi, and L.~{El Ghaoui},
  ``\href{https://people.eecs.berkeley.edu/~tgautam23/publications/ImplicitSequential_Preprint.pdf}{A
  sequential greedy approach for training implicit deep models},'' in {\em
  Proceedings of the 61st IEEE Conference on Decision and Control (CDC)}, 2022.

\bibitem{anderson2022data}
\textbf{B.~G. Anderson} and S.~Sojoudi,
  ``\href{https://brendon-anderson.github.io/files/publications/anderson2022data-long.pdf}{Data-driven
  certification of neural networks with random input noise},'' {\em IEEE
  Transactions on Control of Network Systems (TCNS)}, 2022.

\bibitem{anderson2022towards}
\textbf{B.~G. Anderson}, S.~Pfrommer, and S.~Sojoudi,
  ``\href{https://brendon-anderson.github.io/files/publications/anderson2022towards.pdf}{Towards
  optimal randomized smoothing: A semi-infinite linear programming approach},''
  in {\em ICML Workshop on Formal Verification of Machine Learning (WFVML)},
  2022.
\newblock One of six selected for oral presentation.

\bibitem{anderson2022certified-long}
\textbf{B.~G. Anderson} and S.~Sojoudi,
  ``\href{https://brendon-anderson.github.io/files/publications/anderson2022certified-long.pdf}{Certified
  robustness via locally biased randomized smoothing},'' in {\em Proceedings of
  the 4th Annual Learning for Dynamics and Control Conference (L4DC)}, 2022.

\bibitem{gama2022node}
F.~Gama, \textbf{B.~G. Anderson}, and S.~Sojoudi,
  ``\href{https://arxiv.org/pdf/2106.00089.pdf}{Node-variant graph filters in
  graph neural networks},'' in {\em Proceedings of the IEEE Data Science and
  Learning Workshop (DSLW)}, 2022.

\bibitem{anderson2020tightened}
\textbf{B.~G. Anderson}, Z.~Ma, J.~Li, and S.~Sojoudi,
  ``\href{https://arxiv.org/pdf/2004.00570.pdf}{Tightened convex relaxations
  for neural network robustness certification},'' in {\em Proceedings of the
  59th IEEE Conference on Decision and Control (CDC)}, 2020.

\bibitem{anderson2019global}
\textbf{B.~G. Anderson} and S.~Sojoudi,
  ``\href{https://arxiv.org/pdf/1907.04409.pdf}{Global optimality guarantees
  for nonconvex unsupervised video segmentation},'' in {\em Proceedings of the
  57th Annual Allerton Conference on Communication, Control, and Computing},
  2019.

\bibitem{anderson2019quantifying}
\textbf{B.~G. Anderson}, E.~Loeser, M.~Gee, F.~Ren, S.~Biswas, O.~Turanova,
  M.~Haberland, and A.~L. Bertozzi,
  ``\href{https://arxiv.org/pdf/1905.07655.pdf}{Quantifying robotic swarm
  coverage},'' in {\em Informatics in Control, Automation and Robotics: 15th
  International Conference, ICINCO 2018, Porto, Portugal, July 29--31, 2018,
  Revised Selected Papers}, vol.~613 of {\em Lecture Notes in Electrical
  Engineering}, pp.~276--301, Springer, 2019.

\bibitem{anderson2018quantitative}
\textbf{B.~G. Anderson}, E.~Loeser, M.~Gee, F.~Ren, S.~Biswas, O.~Turanova,
  M.~Haberland, and A.~L. Bertozzi,
  ``\href{https://arxiv.org/pdf/1806.02488.pdf}{Quantitative assessment of
  robotic swarm coverage},'' in {\em Proceedings of the 15th International
  Conference on Informatics in Control, Automation and Robotics (ICINCO)},
  2018.
\newblock \textbf{Shortlisted candidate for Best Student Paper Award}.

\end{thebibliography}
